// ËßÜÈ¢ëËØ≠Èü≥ËΩ¨ÊñáÂ≠óÂäüËÉΩ
const axios = require('axios');
const fs = require('fs');
const path = require('path');

class VideoSpeechToText {
    constructor() {
        this.supportedServices = [
            {
                name: 'Whisper-API',
                endpoint: 'https://api.openai.com/v1/audio/transcriptions',
                requiresKey: true,
                cost: 'paid'
            },
            {
                name: 'AssemblyAI',
                endpoint: 'https://api.assemblyai.com/v2/transcript',
                requiresKey: true,
                cost: 'free-tier'
            },
            {
                name: 'RevAI',
                endpoint: 'https://api.rev.ai/speechtotext/v1/jobs',
                requiresKey: true,
                cost: 'free-tier'
            }
        ];
        
        this.freeServices = [
            {
                name: 'Web Speech API',
                type: 'browser-native',
                description: 'ÊµèËßàÂô®ÂéüÁîüËØ≠Èü≥ËØÜÂà´'
            },
            {
                name: 'SpeechRecognition.js',
                type: 'client-side',
                description: 'ÂÆ¢Êà∑Á´ØËØ≠Èü≥ËØÜÂà´Â∫ì'
            }
        ];
    }

    /**
     * ÊèêÂèñËßÜÈ¢ëÈü≥È¢ëÂπ∂ËΩ¨Êç¢‰∏∫ÊñáÂ≠ó
     * @param {string} videoUrl - ËßÜÈ¢ëURL
     * @param {Object} options - ÈÄâÈ°π
     * @returns {Object} ËΩ¨Êç¢ÁªìÊûú
     */
    async convertVideoToText(videoUrl, options = {}) {
        console.log('üé§ ÂºÄÂßãËßÜÈ¢ëËØ≠Èü≥ËΩ¨ÊñáÂ≠ó...');
        
        try {
            // Ê≠•È™§1: ÊèêÂèñÈü≥È¢ë
            const audioData = await this.extractAudioFromVideo(videoUrl);
            if (!audioData) {
                throw new Error('Êó†Ê≥ïÊèêÂèñËßÜÈ¢ëÈü≥È¢ë');
            }

            // Ê≠•È™§2: ËΩ¨Êç¢‰∏∫ÊñáÂ≠ó
            const textResult = await this.speechToText(audioData, options);
            
            return {
                success: true,
                text: textResult.text,
                confidence: textResult.confidence,
                duration: textResult.duration,
                language: textResult.language,
                method: textResult.method
            };

        } catch (error) {
            console.error('‚ùå ËßÜÈ¢ëËΩ¨ÊñáÂ≠óÂ§±Ë¥•:', error.message);
            return {
                success: false,
                error: error.message,
                suggestion: this.getErrorSuggestion(error.message)
            };
        }
    }

    /**
     * ‰ªéËßÜÈ¢ë‰∏≠ÊèêÂèñÈü≥È¢ë
     * @param {string} videoUrl - ËßÜÈ¢ëURL
     * @returns {Buffer} Èü≥È¢ëÊï∞ÊçÆ
     */
    async extractAudioFromVideo(videoUrl) {
        console.log('üéµ ÊèêÂèñËßÜÈ¢ëÈü≥È¢ë...');
        
        try {
            // ‰ΩøÁî®ffmpegÊèêÂèñÈü≥È¢ëÔºàÈúÄË¶ÅÁ≥ªÁªüÂÆâË£ÖffmpegÔºâ
            const { exec } = require('child_process');
            const util = require('util');
            const execAsync = util.promisify(exec);
            
            const tempAudioFile = path.join(__dirname, 'temp_audio.wav');
            
            // ÊèêÂèñÈü≥È¢ëÂëΩ‰ª§
            const command = `ffmpeg -i "${videoUrl}" -vn -acodec pcm_s16le -ar 16000 -ac 1 "${tempAudioFile}" -y`;
            
            await execAsync(command);
            
            // ËØªÂèñÈü≥È¢ëÊñá‰ª∂
            const audioData = fs.readFileSync(tempAudioFile);
            
            // Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
            fs.unlinkSync(tempAudioFile);
            
            console.log('‚úÖ Èü≥È¢ëÊèêÂèñÊàêÂäü');
            return audioData;

        } catch (error) {
            console.log('‚ö†Ô∏è FFmpegÊèêÂèñÂ§±Ë¥•ÔºåÂ∞ùËØïÂÖ∂‰ªñÊñπÊ≥ï:', error.message);
            
            // Â§áÁî®ÊñπÊ°àÔºöÁõ¥Êé•‰∏ãËΩΩËßÜÈ¢ëÊñá‰ª∂
            try {
                const response = await axios.get(videoUrl, {
                    responseType: 'arraybuffer',
                    timeout: 30000,
                    headers: {
                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15'
                    }
                });
                
                console.log('‚úÖ ËßÜÈ¢ë‰∏ãËΩΩÊàêÂäü');
                return Buffer.from(response.data);
                
            } catch (downloadError) {
                console.error('‚ùå ËßÜÈ¢ë‰∏ãËΩΩÂ§±Ë¥•:', downloadError.message);
                throw new Error('Êó†Ê≥ïËé∑ÂèñËßÜÈ¢ëÊï∞ÊçÆ');
            }
        }
    }

    /**
     * ËØ≠Èü≥ËΩ¨ÊñáÂ≠ó
     * @param {Buffer} audioData - Èü≥È¢ëÊï∞ÊçÆ
     * @param {Object} options - ÈÄâÈ°π
     * @returns {Object} ËΩ¨Êç¢ÁªìÊûú
     */
    async speechToText(audioData, options = {}) {
        console.log('üó£Ô∏è ÂºÄÂßãËØ≠Èü≥ËØÜÂà´...');
        
        // Â∞ùËØïÂÖçË¥πÊñπÊ°à
        const freeResult = await this.tryFreeSpeechRecognition(audioData, options);
        if (freeResult.success) {
            return freeResult;
        }
        
        // Â∞ùËØï‰ªòË¥πAPIÔºàÂ¶ÇÊûúÊúâAPI KeyÔºâ
        const apiResult = await this.tryPaidSpeechRecognition(audioData, options);
        if (apiResult.success) {
            return apiResult;
        }
        
        throw new Error('ÊâÄÊúâËØ≠Èü≥ËØÜÂà´ÊñπÊ°àÈÉΩÂ§±Ë¥•‰∫Ü');
    }

    /**
     * Â∞ùËØïÂÖçË¥πËØ≠Èü≥ËØÜÂà´
     * @param {Buffer} audioData - Èü≥È¢ëÊï∞ÊçÆ
     * @param {Object} options - ÈÄâÈ°π
     * @returns {Object} ËØÜÂà´ÁªìÊûú
     */
    async tryFreeSpeechRecognition(audioData, options) {
        console.log('üÜì Â∞ùËØïÂÖçË¥πËØ≠Èü≥ËØÜÂà´ÊñπÊ°à...');
        
        try {
            // ÊñπÊ°à1: ‰ΩøÁî®Web Speech APIÔºàÈúÄË¶ÅÊµèËßàÂô®ÁéØÂ¢ÉÔºâ
            if (options.useBrowserAPI) {
                return await this.useWebSpeechAPI(audioData);
            }
            
            // ÊñπÊ°à2: ‰ΩøÁî®Êú¨Âú∞ËØ≠Èü≥ËØÜÂà´Â∫ì
            return await this.useLocalSpeechRecognition(audioData);
            
        } catch (error) {
            console.log('‚ö†Ô∏è ÂÖçË¥πÊñπÊ°àÂ§±Ë¥•:', error.message);
            return { success: false, error: error.message };
        }
    }

    /**
     * ‰ΩøÁî®Web Speech API
     * @param {Buffer} audioData - Èü≥È¢ëÊï∞ÊçÆ
     * @returns {Object} ËØÜÂà´ÁªìÊûú
     */
    async useWebSpeechAPI(audioData) {
        // Ëøô‰∏™ÊñπÊ≥ïÈúÄË¶ÅÂú®ÊµèËßàÂô®ÁéØÂ¢É‰∏≠ËøêË°å
        return {
            success: false,
            error: 'Web Speech APIÈúÄË¶ÅÂú®ÊµèËßàÂô®ÁéØÂ¢É‰∏≠‰ΩøÁî®',
            suggestion: 'ËØ∑Âú®ÊµèËßàÂô®‰∏≠Ë∞ÉÁî®Ê≠§ÂäüËÉΩ'
        };
    }

    /**
     * ‰ΩøÁî®Êú¨Âú∞ËØ≠Èü≥ËØÜÂà´
     * @param {Buffer} audioData - Èü≥È¢ëÊï∞ÊçÆ
     * @returns {Object} ËØÜÂà´ÁªìÊûú
     */
    async useLocalSpeechRecognition(audioData) {
        try {
            // ‰ΩøÁî®node-speech-recognitionÊàñÁ±ª‰ººÂ∫ì
            const SpeechRecognition = require('node-speech-recognition');
            
            const recognition = new SpeechRecognition({
                language: 'zh-CN',
                continuous: true,
                interimResults: false
            });
            
            return new Promise((resolve, reject) => {
                recognition.on('result', (result) => {
                    resolve({
                        success: true,
                        text: result.transcript,
                        confidence: result.confidence || 0.8,
                        duration: audioData.length / 16000, // ‰º∞ÁÆóÊó∂Èïø
                        language: 'zh-CN',
                        method: 'local-speech-recognition'
                    });
                });
                
                recognition.on('error', (error) => {
                    reject(error);
                });
                
                recognition.start();
                recognition.feed(audioData);
                recognition.stop();
            });
            
        } catch (error) {
            console.log('‚ö†Ô∏è Êú¨Âú∞ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•:', error.message);
            return { success: false, error: error.message };
        }
    }

    /**
     * Â∞ùËØï‰ªòË¥πAPI
     * @param {Buffer} audioData - Èü≥È¢ëÊï∞ÊçÆ
     * @param {Object} options - ÈÄâÈ°π
     * @returns {Object} ËØÜÂà´ÁªìÊûú
     */
    async tryPaidSpeechRecognition(audioData, options) {
        console.log('üí∞ Â∞ùËØï‰ªòË¥πAPIÊñπÊ°à...');
        
        // Ê£ÄÊü•ÊòØÂê¶ÊúâAPI Key
        const apiKey = process.env.OPENAI_API_KEY || options.apiKey;
        if (!apiKey) {
            return { success: false, error: 'ÈúÄË¶ÅAPI KeyÊâçËÉΩ‰ΩøÁî®‰ªòË¥πÊúçÂä°' };
        }
        
        try {
            // ‰ΩøÁî®OpenAI Whisper API
            const response = await axios.post(
                'https://api.openai.com/v1/audio/transcriptions',
                {
                    file: audioData,
                    model: 'whisper-1',
                    language: options.language || 'zh',
                    response_format: 'json'
                },
                {
                    headers: {
                        'Authorization': `Bearer ${apiKey}`,
                        'Content-Type': 'multipart/form-data'
                    },
                    timeout: 60000
                }
            );
            
            return {
                success: true,
                text: response.data.text,
                confidence: 0.95, // WhisperÈÄöÂ∏∏ÊúâÂæàÈ´òÁöÑÂáÜÁ°ÆÂ∫¶
                duration: audioData.length / 16000,
                language: options.language || 'zh',
                method: 'openai-whisper'
            };
            
        } catch (error) {
            console.log('‚ö†Ô∏è OpenAI APIÂ§±Ë¥•:', error.message);
            return { success: false, error: error.message };
        }
    }

    /**
     * Ëé∑ÂèñÈîôËØØÂª∫ËÆÆ
     * @param {string} error - ÈîôËØØ‰ø°ÊÅØ
     * @returns {string} Âª∫ËÆÆ
     */
    getErrorSuggestion(error) {
        if (error.includes('ffmpeg')) {
            return 'ËØ∑ÂÆâË£ÖFFmpeg: brew install ffmpeg (macOS) Êàñ apt-get install ffmpeg (Ubuntu)';
        } else if (error.includes('API Key')) {
            return 'ËØ∑ËÆæÁΩÆOPENAI_API_KEYÁéØÂ¢ÉÂèòÈáèÊàñÊèê‰æõAPI Key';
        } else if (error.includes('ÁΩëÁªú')) {
            return 'ËØ∑Ê£ÄÊü•ÁΩëÁªúËøûÊé•ÔºåÊàñÁ®çÂêéÈáçËØï';
        } else {
            return 'Âª∫ËÆÆ‰ΩøÁî®Âú®Á∫øÂ∑•ÂÖ∑Â¶ÇKapwingÊàñDictationerËøõË°åËΩ¨Êç¢';
        }
    }

    /**
     * Ëé∑ÂèñÂèØÁî®ÁöÑÂÖçË¥πÊñπÊ°à
     * @returns {Array} ÂÖçË¥πÊñπÊ°àÂàóË°®
     */
    getFreeOptions() {
        return [
            {
                name: 'ÊµèËßàÂô®ÂéüÁîüËØÜÂà´',
                description: '‰ΩøÁî®Web Speech APIÔºåÊó†ÈúÄÂÆâË£Ö',
                pros: ['ÂÆåÂÖ®ÂÖçË¥π', 'Êó†ÈúÄAPI Key', 'ÊîØÊåÅÂÆûÊó∂ËØÜÂà´'],
                cons: ['ÈúÄË¶ÅÊµèËßàÂô®ÁéØÂ¢É', 'ÂáÜÁ°ÆÂ∫¶‰∏ÄËà¨', 'ÈúÄË¶ÅÁî®Êà∑ÊéàÊùÉ'],
                implementation: 'client-side'
            },
            {
                name: 'Âú®Á∫øÂ∑•ÂÖ∑',
                description: '‰ΩøÁî®Á¨¨‰∏âÊñπÂÖçË¥πÊúçÂä°',
                pros: ['È´òÂáÜÁ°ÆÂ∫¶', 'ÊîØÊåÅÂ§öËØ≠Ë®Ä', 'Êó†ÈúÄÂÆâË£Ö'],
                cons: ['Êúâ‰ΩøÁî®ÈôêÂà∂', 'ÈúÄË¶Å‰∏ä‰º†Êñá‰ª∂', '‰æùËµñÁΩëÁªú'],
                services: ['Kapwing', 'Dictationer', 'Clideo']
            },
            {
                name: 'Êú¨Âú∞ËØÜÂà´',
                description: '‰ΩøÁî®ÂºÄÊ∫êËØ≠Èü≥ËØÜÂà´Â∫ì',
                pros: ['ÈöêÁßÅÂÆâÂÖ®', 'Êó†ÁΩëÁªú‰æùËµñ', 'ÂèØÂÆöÂà∂'],
                cons: ['ÈúÄË¶ÅÂÆâË£Ö‰æùËµñ', 'ÂáÜÁ°ÆÂ∫¶‰∏ÄËà¨', 'ËµÑÊ∫êÊ∂àËÄóÂ§ß'],
                libraries: ['SpeechRecognition', 'PocketSphinx']
            }
        ];
    }
}

// ÊµãËØïÂáΩÊï∞
async function testVideoSpeechToText() {
    console.log('üé§ ÊµãËØïËßÜÈ¢ëËØ≠Èü≥ËΩ¨ÊñáÂ≠ó');
    console.log('='.repeat(50));
    
    const converter = new VideoSpeechToText();
    const testVideoUrl = 'https://example.com/test-video.mp4';
    
    try {
        const result = await converter.convertVideoToText(testVideoUrl);
        
        if (result.success) {
            console.log('\nüéâ ËΩ¨Êç¢ÊàêÂäüÔºÅ');
            console.log('üìä ÁªìÊûú:');
            console.log('   ÊñáÊú¨:', result.text);
            console.log('   ÁΩÆ‰ø°Â∫¶:', result.confidence);
            console.log('   Êó∂Èïø:', result.duration + 'Áßí');
            console.log('   ËØ≠Ë®Ä:', result.language);
            console.log('   ÊñπÊ≥ï:', result.method);
        } else {
            console.log('\n‚ùå ËΩ¨Êç¢Â§±Ë¥•:', result.error);
            console.log('üí° Âª∫ËÆÆ:', result.suggestion);
        }
    } catch (error) {
        console.log('\n‚ùå ÊµãËØïÂ§±Ë¥•:', error.message);
    }
    
    console.log('\nüìã ÂÖçË¥πÊñπÊ°à:');
    const freeOptions = converter.getFreeOptions();
    freeOptions.forEach((option, index) => {
        console.log(`${index + 1}. ${option.name}`);
        console.log(`   ÊèèËø∞: ${option.description}`);
        console.log(`   ‰ºòÁÇπ: ${option.pros.join(', ')}`);
        console.log(`   Áº∫ÁÇπ: ${option.cons.join(', ')}`);
        console.log('');
    });
}

if (require.main === module) {
    testVideoSpeechToText().catch(console.error);
}

module.exports = VideoSpeechToText;
